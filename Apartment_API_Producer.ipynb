{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import StringType, IntegerType, TimestampType, DateType, DoubleType, StructType, StructField\n# Schema for Landlord JSON\nlandlord_schema = StructType([\n            StructField(\"Landlord_id\", IntegerType(), False),\n            StructField(\"Password\", StringType(), True),\n            StructField(\"Landlord_name\", StringType(), False),\n            StructField(\"Address_line_1\", StringType(), False),\n            StructField(\"City\", StringType(), False),\n            StructField(\"Post_code\", StringType(), True),\n            StructField(\"Region\", StringType(), True),\n            StructField(\"event_time\", StringType(), True)])\n\n# Schema for building JSON\nbuilding_schema = StructType([\n            StructField(\"Building_id\", IntegerType(), False),\n            StructField(\"Building_name\", StringType(), True),\n            StructField(\"Landlord_id\", IntegerType(), False),\n            StructField(\"Address_line_1\", StringType(), False),\n            StructField(\"City\", StringType(), False),\n            StructField(\"Post_code\", StringType(), True),\n            StructField(\"Region\", StringType(), True),\n            StructField(\"event_time\", StringType(), True)])\n\n# Schema for Apartment JSON\napartment_schema = StructType([\n            StructField(\"Building_id\", IntegerType(), True),\n            StructField(\"Apartment_number\", IntegerType(), True),\n            StructField(\"Type\", StringType(), True),\n            StructField(\"Rent_fee\", StringType(), True),\n            StructField(\"Building_name\", StringType(), True),\n            StructField(\"Appt_details\", StringType(), True),\n            StructField(\"event_time\", StringType(), True)])\n\n# Schema for Contractor\ncontractor_schema = StructType([\n            StructField(\"Contract_id\", IntegerType(), False),\n            StructField(\"Name\", StringType(), True),\n            StructField(\"Address_line_1\", StringType(), False),\n            StructField(\"City\", StringType(), False),\n            StructField(\"Post_code\", StringType(), True),\n            StructField(\"Region\", StringType(), True)])\n\n# Schema for Tenant\ntenant_schema = StructType([\n            StructField(\"Tenant_id\", IntegerType(), False),\n            StructField(\"First_name\", StringType(), True),\n            StructField(\"Last_name\", StringType(), False),\n            StructField(\"Ssn\", StringType(), True),\n            StructField(\"Phone\", StringType(), True),\n            StructField(\"Email\", StringType(), True), \n            StructField(\"Mobile\", StringType(), True)])\n\n# Schema for Lease \nlease_schema = StructType([\n            StructField(\"Lease_id\", IntegerType(), False),\n            StructField(\"Start\", StringType(), True),\n            StructField(\"End\", StringType(), False),\n            StructField(\"Deposit\", StringType(), True),\n            StructField(\"Tenant_id\", IntegerType(), True),\n            StructField(\"Apartment_id\", IntegerType(), True)])\n\n# Schema  for Rent\nrent_schema = StructType([\n            StructField(\"Rent_id\", IntegerType(), False),\n            StructField(\"Rent_fee\", StringType(), True),\n            StructField(\"Late_fee\", StringType(), False),\n            StructField(\"Due_date\", StringType(), True),\n            StructField(\"Lease_id\", IntegerType(), True),\n            StructField(\"Pay_id\", IntegerType(), True)])\n\n# Schema for Payment\npayment_schema = StructType([\n            StructField(\"Payment_id\", IntegerType(), False),\n            StructField(\"Pay_date\", StringType(), True),\n            StructField(\"Pay_amount\", StringType(), False),\n            StructField(\"Method\", StringType(), True),\n            StructField(\"Rent_id\", IntegerType(), True)])\n\n# Schema for Apartment Maintenance\napt_maintenance_schema = StructType([\n            StructField(\"Maintenance_id\", IntegerType(), False),\n            StructField(\"Apartment_number\", IntegerType(), True),\n            StructField(\"Mdate\", StringType(), False),\n            StructField(\"Issue_reported\", StringType(), True),\n            StructField(\"Contractor_id\", IntegerType(), True), \n            StructField(\"Resolution\", StringType(), True), \n            StructField(\"Status\", StringType(), True),\n            StructField(\"Charges_incurred\", StringType(), True)])\n\n# Schema for Building Maintenance\nbuilding_maintenance_schema = StructType([\n            StructField(\"Maintenance_id\", IntegerType(), False),\n            StructField(\"Building_name\", StringType(), True),\n            StructField(\"Ndate\", StringType(), False),\n            StructField(\"Issue_reported\", StringType(), True),\n            StructField(\"Contractor_id\", IntegerType(), True), \n            StructField(\"Resolution\", StringType(), True), \n            StructField(\"Status\", StringType(), True)])\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["project_Path = \"/FileStore/apartment/\"\napi_key =\"ebd69250\"\nlandlord_url = \"https://my.api.mockaroo.com/landlord.json?key=\" + api_key\nlandlord_Path = \"/FileStore/apartment/landlord/inprogress/\"\n\nbuilding_url = \"https://my.api.mockaroo.com/building.json?key=\" + api_key\nbuilding_Path = \"/FileStore/apartment/building/inprogress/\"\n\napartment_url = \"https://my.api.mockaroo.com/apartment.json?key=\" + api_key\napartment_Path = \"/FileStore/apartment/apartment/inprogress/\"\n\ncontractor_url = \"https://my.api.mockaroo.com/contractor_table.json?key=\" + api_key\ncontractor_Path = \"/FileStore/apartment/contractor/inprogress/\"\n\ntenant_url = \"https://my.api.mockaroo.com/tenant.json?key=\" + api_key\ntenant_Path = \"/FileStore/apartment/tenant/inprogress/\"\n\nlease_url = \"https://my.api.mockaroo.com/lease.json?key=\" + api_key\nlease_Path = \"/FileStore/apartment/lease/inprogress/\"\n\nrent_url = \"https://my.api.mockaroo.com/rent.json?key=\" + api_key\nrent_Path = \"/FileStore/apartment/rent/inprogress/\"\n\npayment_url = \"https://my.api.mockaroo.com/payment.json?key=\" + api_key\npayment_Path = \"/FileStore/apartment/payment/inprogress/\"\n\napartment_maintenance_url = \"https://my.api.mockaroo.com/apartment_maintenance.json?key=\" + api_key\napartment_maintenance_Path = \"/FileStore/apartment/apartment_maintenance/inprogress/\"\n\nbuilding_maintenance_url = \"https://my.api.mockaroo.com/building_maintenance.json?key=\" + api_key\nbuilding_maintenance_Path = \"/FileStore/apartment/building_maintenance/inprogress/\"\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Read API from Kafka, Event hub, Sockets (for testing) and files . One  need to read data from API and store in file else these structures before processing by spark sreaming\n# create the base directory to store csv files\ndbutils.fs.rm(project_Path,recurse=True)\ndbutils.fs.mkdirs(landlord_Path)\ndbutils.fs.mkdirs(building_Path)\ndbutils.fs.mkdirs(apartment_Path)\ndbutils.fs.mkdirs(contractor_Path)\ndbutils.fs.mkdirs(tenant_Path)\ndbutils.fs.mkdirs(lease_Path)\ndbutils.fs.mkdirs(rent_Path)\ndbutils.fs.mkdirs(payment_Path)\ndbutils.fs.mkdirs(apartment_maintenance_Path)\ndbutils.fs.mkdirs(building_maintenance_Path)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Save csv file from api url\n# '/FileStore/apartment/inprogress/'\ndef getCSV_FromUrl(url, schema, path_to_save):  \n  df = spark.createDataFrame(pd.read_csv(url, lineterminator='\\n'), schema)\n  \n  ts = time.time()\n  st = datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d_%H_%M')\n  df_with_batch = df.withColumn(\"fetch_time\", lit(datetime.datetime.fromtimestamp(ts).strftime('%Y_%m_%d_%H_%M_%S')))\n  fileName = path_to_save + st + '.tmp'\n  fileprefix = path_to_save\n  df_with_batch.coalesce(1).write.format(\"com.databricks.spark.csv\") \\\n    .option(\"header\", True) \\\n    .option('quote', '\"')  \\\n    .save(fileName)  #saved to the FileStore\n    \n  fileList =  dbutils.fs.ls(fileName)\n\n  csvFileLocation = ''\n  for fileInfo in fileList:   \n    if \".csv\" in fileInfo.path:\n      print(\"this file is csv file..\" )\n      print(fileInfo.path)\n      csvFileLocation = fileprefix + fileInfo.name      \n      dbutils.fs.cp(fileInfo.path,fileprefix)\n      dbutils.fs.rm(fileName,recurse=True)\n      print(csvFileLocation)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["import schedule\nimport time\nimport requests\nimport datetime\nimport pandas as pd\nfrom pyspark.sql.functions import lit\n \ndef job():\n  print(\"calling CSV load function\")\n  getCSV_FromUrl(landlord_url, landlord_schema, landlord_Path)\n  getCSV_FromUrl(building_url, building_schema, building_Path)\n  getCSV_FromUrl(apartment_url, apartment_schema, apartment_Path)\n  getCSV_FromUrl(contractor_url, contractor_schema, contractor_Path)\n  getCSV_FromUrl(tenant_url, tenant_schema, tenant_Path)\n  getCSV_FromUrl(lease_url, lease_schema, lease_Path)\n  getCSV_FromUrl(rent_url, rent_pre_schema, rent_Path)\n  getCSV_FromUrl(payment_url, payment_pre_schema, payment_Path)\n  getCSV_FromUrl(apartment_maintenance_url, apt_maintenance_schema, apartment_maintenance_Path)\n  getCSV_FromUrl(building_maintenance_url, building_maintenance_schema, building_maintenance_Path)\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Entry point\nschedule.every(30).seconds.do(job)\nwhile True:\n    schedule.run_pending()\n    time.sleep(1)"],"metadata":{},"outputs":[],"execution_count":6}],"metadata":{"name":"SCV_streaming","notebookId":2268477664179889},"nbformat":4,"nbformat_minor":0}
